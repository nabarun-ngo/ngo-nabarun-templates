name: JMeter Load Test 

on:
  workflow_call:
    inputs:
      script:
        description: 'Path of the jmx script(including .jmx ext)'
        type: string
        required: true
      users:
        description: "Concurrent users"
        required: true
        type: number
      rampup:
        description: "Ramp-up time (seconds)"
        required: true
        type: number
      loops:
        description: "Loop count per user"
        required: true
        type: number
      lifetime:
        description: 'Thread lifetime'
        type: number
        required: true
      target_url:
        description: "Target base URL (without protocol)"
        required: true
        type: string
    secrets:
      JWT_TOKEN:
        required: true

jobs:
  jmeter:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Install JMeter
        run: |
          sudo apt update
          sudo apt install -y jmeter

      - name: Run JMeter Load Test
        run: |
          jmeter -n \
            -t loadtests/${{ inputs.script }} \
            -JUSERS=${{ inputs.users }} \
            -JRAMP_UP=${{ inputs.rampup }} \
            -JLOOPS=${{ inputs.loops }} \
            -JLIFETIME=${{ inputs.lifetime }} \
            -JTARGET_HOST=${{ inputs.target_url }} \
            -JJWT_TOKEN=${{ secrets.JWT_TOKEN }} \
            -JAPI_KEY=${{ secrets.API_KEY }} \
            -l results.jtl \
            -e -o report

      - name: Upload JMeter HTML Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: jmeter-report-${{ github.run_number }}
          path: report/
          retention-days: 30

      - name: Upload JTL Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: jmeter-results-${{ github.run_number }}
          path: results.jtl
          retention-days: 30

      # Deploy Report to GitHub Pages
      - name: Deploy Report to GitHub Pages
        if: always()
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./report
          destination_dir: reports/${{ github.run_number }}
          keep_files: true

      # Create Performance Summary
      - name: Generate Performance Summary
        if: always()
        run: |
          echo "## ðŸ“Š Performance Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Test Configuration:**" >> $GITHUB_STEP_SUMMARY
          echo "- Users: ${{ inputs.users }}" >> $GITHUB_STEP_SUMMARY
          echo "- Ramp-up: ${{ inputs.rampup }}s" >> $GITHUB_STEP_SUMMARY
          echo "- Loops: ${{ inputs.loops }}" >> $GITHUB_STEP_SUMMARY
          echo "- Target: https://${{ inputs.target_url }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Extract key metrics from JTL file
          if [ -f results.jtl ]; then
            echo "**Quick Stats:**" >> $GITHUB_STEP_SUMMARY
            
            # Total samples
            TOTAL=$(grep -c "^[0-9]" results.jtl || echo "0")
            echo "- Total Requests: $TOTAL" >> $GITHUB_STEP_SUMMARY
            
            # Success rate
            SUCCESS=$(grep ",true," results.jtl | wc -l || echo "0")
            if [ "$TOTAL" -gt 0 ]; then
              SUCCESS_RATE=$(awk "BEGIN {printf \"%.2f\", ($SUCCESS / $TOTAL) * 100}")
              echo "- Success Rate: ${SUCCESS_RATE}%" >> $GITHUB_STEP_SUMMARY
            fi
            
            # Average response time
            AVG_TIME=$(awk -F',' '{sum+=$2; count++} END {if(count>0) printf "%.0f", sum/count; else print "0"}' results.jtl)
            echo "- Avg Response Time: ${AVG_TIME}ms" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ“ˆ [View Full HTML Report](https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/reports/${{ github.run_number }}/index.html)" >> $GITHUB_STEP_SUMMARY

      # Comment on PR with results (if triggered by PR)
      - name: Comment PR
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            let comment = `## ðŸš€ Performance Test Results\n\n`;
            comment += `**Configuration:**\n`;
            comment += `- Users: ${{ inputs.users }}\n`;
            comment += `- Ramp-up: ${{ inputs.rampup }}s\n`;
            comment += `- Loops: ${{ inputs.loops }}\n`;
            comment += `- Target: https://${{ inputs.target_url }}\n\n`;
            
            if (fs.existsSync('results.jtl')) {
              const content = fs.readFileSync('results.jtl', 'utf8');
              const lines = content.split('\n').filter(l => l.startsWith('timeStamp') === false && l.trim() !== '');
              const total = lines.length;
              const success = lines.filter(l => l.includes(',true,')).length;
              const successRate = ((success / total) * 100).toFixed(2);
              
              comment += `**Results:**\n`;
              comment += `- âœ… Success Rate: ${successRate}%\n`;
              comment += `- ðŸ“Š Total Requests: ${total}\n`;
              comment += `- âœ”ï¸ Successful: ${success}\n`;
              comment += `- âŒ Failed: ${total - success}\n\n`;
            }
            
            comment += `ðŸ“ˆ [View Detailed Report](https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/reports/${{ github.run_number }}/index.html)\n`;
            comment += `ðŸ“¦ [Download Artifacts](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})\n`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

      # Check performance thresholds
      - name: Check Performance Thresholds
        if: always()
        run: |
          if [ -f results.jtl ]; then
            # Calculate metrics
            TOTAL=$(grep -c "^[0-9]" results.jtl || echo "0")
            SUCCESS=$(grep ",true," results.jtl | wc -l || echo "0")
            
            if [ "$TOTAL" -gt 0 ]; then
              SUCCESS_RATE=$(awk "BEGIN {printf \"%.2f\", ($SUCCESS / $TOTAL) * 100}")
              AVG_TIME=$(awk -F',' '{sum+=$2; count++} END {if(count>0) printf "%.0f", sum/count; else print "0"}' results.jtl)
              
              echo "Success Rate: ${SUCCESS_RATE}%"
              echo "Average Response Time: ${AVG_TIME}ms"
              
              # Set thresholds
              MIN_SUCCESS_RATE=95
              MAX_AVG_TIME=2000
              
              # Check thresholds
              if (( $(echo "$SUCCESS_RATE < $MIN_SUCCESS_RATE" | bc -l) )); then
                echo "âŒ FAILED: Success rate ${SUCCESS_RATE}% is below threshold ${MIN_SUCCESS_RATE}%"
                exit 1
              fi
              
              if [ "$AVG_TIME" -gt "$MAX_AVG_TIME" ]; then
                echo "âŒ FAILED: Average response time ${AVG_TIME}ms exceeds threshold ${MAX_AVG_TIME}ms"
                exit 1
              fi
              
              echo "âœ… PASSED: All performance thresholds met"
            fi
          fi
